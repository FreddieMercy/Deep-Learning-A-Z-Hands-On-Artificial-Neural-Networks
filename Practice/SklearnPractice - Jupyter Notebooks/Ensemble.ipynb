{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9523809523809523\n",
      "0.9523809523809523\n",
      "0.9619047619047618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "# ensemble means \"take mean\"\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "\n",
    "data_i, targeti = load_iris(return_X_y=True)\n",
    "data_train, data_test, target_train, target_test = train_test_split(data_i, targeti, random_state=42,\n",
    "                                                                    stratify=targeti, test_size=0.7)\n",
    "\n",
    "bagging = BaggingClassifier(max_samples=0.5,  # half rows\n",
    "                            max_features=0.5,  # half columns\n",
    "                            base_estimator=KNeighborsClassifier())\n",
    "\n",
    "# better than Bagging: can define how many estimators, rather than unknown number of estimators\n",
    "# worse than Bagging: cannot define the base_estimator\n",
    "rndForest = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "exTree = ExtraTreesClassifier(max_samples=0.5,  # half rows\n",
    "                              max_features=0.5,  # half columns\n",
    "                              n_estimators=10)\n",
    "\n",
    "# Basically the same\n",
    "bagging.fit(data_train, target_train)\n",
    "rndForest.fit(data_train, target_train)\n",
    "exTree.fit(data_train, target_train)\n",
    "\n",
    "print(cross_val_score(bagging, data_test, target_test, cv=5).mean())\n",
    "print(cross_val_score(rndForest, data_test, target_test, cv=5).mean())\n",
    "print(cross_val_score(exTree, data_test, target_test, cv=5).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 0 0 2 1 1 1 1 1 0 2 1 0 2 1 0 0 0 0 2 2 1 1 1 1 0 2 1 2 1 2 0 1 1\n",
      " 0 2 2 2 0 2 1 0 1 0 0 0 1 0 0 2 2 2 0 2 1 0 2 2 0 2 2 2 2 1 2 0 2 1 2 0 0\n",
      " 2 1 0 1 0 2 2 1 1 2 1 0 1 1 1 0 0 2 1 2 1 2 1 2 1 0 0 1 0 1 1]\n",
      "[0 0 2 0 0 0 2 1 1 1 1 1 0 2 1 0 2 1 0 0 0 0 2 2 1 1 1 1 0 2 1 2 1 1 0 1 1\n",
      " 0 2 2 2 0 2 1 0 1 0 0 0 1 0 0 2 1 2 0 2 1 0 2 2 0 2 2 2 2 1 2 0 2 1 2 0 0\n",
      " 2 1 0 1 0 2 2 1 1 2 1 0 1 1 1 0 0 2 1 2 2 2 1 2 1 0 0 1 0 1 1]\n",
      "[0 0 2 0 0 0 2 1 1 1 1 1 0 2 1 0 2 1 0 0 0 0 2 2 1 1 2 1 0 2 1 2 1 1 0 1 1\n",
      " 0 2 2 2 0 2 1 0 1 0 0 0 1 0 0 2 1 2 0 2 1 0 2 2 0 2 2 2 2 1 2 0 2 1 2 0 0\n",
      " 2 1 0 1 0 2 2 1 1 2 1 0 1 1 1 0 0 2 1 2 2 2 1 2 1 0 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_predict(bagging, data_test, target_test, cv=5))\n",
    "print(cross_val_predict(rndForest, data_test, target_test, cv=5))\n",
    "print(cross_val_predict(exTree, data_test, target_test, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9714285714285714\n",
      "0.9523809523809523\n",
      "[0 0 2 0 0 0 2 1 1 1 1 1 0 2 1 0 2 1 0 0 0 0 2 2 1 1 2 1 0 2 1 2 1 1 0 2 1\n",
      " 0 1 2 2 0 2 1 0 1 0 0 0 1 0 0 2 2 2 0 2 1 0 2 2 0 2 2 2 2 1 2 0 2 2 2 0 0\n",
      " 2 1 0 1 0 2 2 1 1 2 1 0 1 1 1 0 0 2 1 2 2 2 1 2 1 0 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)  # strengthen weakness\n",
    "ada_clf.fit(data_train, target_train)\n",
    "\n",
    "print(ada_clf.score(data_test, target_test))\n",
    "print(cross_val_score(ada_clf, data_test, target_test, cv=5).mean())\n",
    "print(cross_val_predict(ada_clf, data_test, target_test, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9428571428571428\n",
      "0.9523809523809523\n",
      "[0 0 2 0 0 0 2 1 1 1 1 1 0 2 1 0 2 1 0 0 0 0 2 2 1 1 2 1 0 2 1 2 1 1 0 1 1\n",
      " 0 2 2 2 0 2 1 0 1 0 0 0 1 0 0 2 1 2 0 2 1 0 2 2 0 2 2 2 2 1 2 0 2 1 2 0 0\n",
      " 2 1 0 1 0 2 2 1 1 2 1 0 1 1 1 0 0 2 1 2 2 2 1 2 1 0 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=100)\n",
    "gbc.fit(data_train, target_train)\n",
    "\n",
    "print(gbc.score(data_test, target_test))\n",
    "print(cross_val_score(gbc, data_test, target_test, cv=5).mean())\n",
    "print(cross_val_predict(gbc, data_test, target_test, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9278549928225018\n",
      "0.9251851432530074\n",
      "[-1.21625101e-04 -1.21625101e-04  2.02461465e+00 -1.21625101e-04\n",
      " -1.21625101e-04 -1.21625101e-04  1.99825322e+00  1.08891462e+00\n",
      "  8.22063846e-01  9.82651125e-01  9.84849620e-01  9.29685159e-01\n",
      " -1.21625101e-04  2.00143557e+00  9.72966777e-01 -1.21625101e-04\n",
      "  1.71339666e+00  9.99053070e-01 -1.21625101e-04 -1.21625101e-04\n",
      " -1.21625101e-04 -4.23738530e-04  1.94885833e+00  2.03346285e+00\n",
      "  1.01180741e+00  1.00741305e+00  1.79850294e+00  1.00240761e+00\n",
      " -4.23738530e-04  1.94396564e+00  1.68211090e+00  2.00189718e+00\n",
      "  1.00747087e+00  9.99429148e-01  5.23189001e-04  1.68350937e+00\n",
      "  9.90413789e-01 -4.23738530e-04  1.93903375e+00  1.99823734e+00\n",
      "  2.00213187e+00 -4.23738530e-04  1.99700378e+00  9.98702974e-01\n",
      "  2.80764727e-04  1.00381518e+00  2.80764727e-04  2.80764727e-04\n",
      "  2.80764727e-04  9.69247481e-01  2.80764727e-04  1.09882778e-03\n",
      "  1.99924267e+00  1.01051826e+00  1.99784143e+00  2.80764727e-04\n",
      "  2.00021800e+00  9.98992152e-01  1.42530170e-03  2.00079286e+00\n",
      "  1.99807467e+00  2.80764727e-04  2.00028882e+00  1.99720000e+00\n",
      "  1.99825841e+00  1.99824080e+00  1.01015546e+00  1.98724581e+00\n",
      "  1.71132952e-04  2.00229999e+00  1.75506757e+00  2.00034111e+00\n",
      " -1.17065272e-03  1.71132952e-04  1.99169247e+00  9.99358784e-01\n",
      "  1.71132952e-04  9.99747634e-01 -1.17065272e-03  1.99762064e+00\n",
      "  2.00411713e+00  1.00865577e+00  9.48849382e-01  2.00677553e+00\n",
      "  9.85809768e-01  4.09961203e-05  9.99511273e-01  9.99511273e-01\n",
      "  1.03581487e+00  2.56763036e-03  4.09961203e-05  1.98711887e+00\n",
      "  1.23526840e+00  2.02576020e+00  2.08450633e+00  2.03648542e+00\n",
      "  1.16136546e+00  2.00442042e+00  1.00226689e+00  4.09961203e-05\n",
      "  1.39262105e-02  1.17708645e+00  4.09961203e-05  9.99457002e-01\n",
      "  1.00320367e+00]\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=100)  # it is a decision tree, so it could be un-stable?\n",
    "gbr.fit(data_train, target_train)\n",
    "\n",
    "print(gbr.score(data_test, target_test))\n",
    "print(cross_val_score(gbr, data_test, target_test, cv=5).mean())\n",
    "print(cross_val_predict(gbr, data_test, target_test, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9047619047619048\n",
      "0.9619047619047618\n",
      "[0 0 2 0 0 0 2 1 1 1 1 1 0 2 1 0 2 1 0 0 0 0 2 2 1 1 2 1 0 2 1 2 1 1 0 1 1\n",
      " 0 2 2 2 0 2 1 0 1 0 0 0 1 0 0 2 2 2 0 2 1 0 2 2 0 2 2 2 2 1 2 0 2 2 2 0 0\n",
      " 2 1 0 1 0 2 2 1 1 2 1 0 1 1 1 0 0 2 1 2 2 2 1 2 1 0 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "vc = VotingClassifier(\n",
    "    estimators=[(\"someone\", rndForest), (\"bagging\", bagging), (\"LogisticRegression\", LogisticRegression()),\n",
    "                (\"SVC\", svm.SVC())],  # like Pipeline\n",
    "    # hard vote: 少数服从多数， 如果平票，那按字母排列选第一个\n",
    "    # soft vote：take average\n",
    "    voting=\"hard\",\n",
    "    weights=[2, 1, 2, 1])\n",
    "\n",
    "vc.fit(data_train, target_train)\n",
    "\n",
    "print(vc.score(data_test, target_test))\n",
    "print(cross_val_score(vc, data_test, target_test, cv=5).mean())\n",
    "print(cross_val_predict(vc, data_test, target_test, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919950556449805\n",
      "0.9170393061332138\n",
      "[ 0.02355464  0.12214374  1.75632896  0.03087309  0.06342169 -0.00372767\n",
      "  1.7554274   1.20177498  1.23186683  1.14809371  1.13109518  1.32618274\n",
      "  0.11523227  2.12312881  1.02127014 -0.05081407  1.71945602  1.02648813\n",
      "  0.04677188  0.03824467  0.08749698  0.13576185  1.68296142  1.53909217\n",
      "  1.2384281   1.27040085  1.51241599  1.15471058  0.26480985  1.91373247\n",
      "  0.86676884  1.74125646  1.26770572  1.33029681  0.08758937  0.86342452\n",
      "  1.11178497  0.08129878  1.49495255  1.85027691  1.91777894  0.0286841\n",
      "  1.91699821  1.33815013  0.10722927  1.16157637  0.042848    0.0504366\n",
      "  0.01760286  1.25007095  0.06451276  0.04348767  1.79723432  1.40575314\n",
      "  1.62983006 -0.03149432  1.67751472  0.92409511 -0.0943819   1.51009515\n",
      "  1.72839503  0.05708036  1.63000767  1.69138994  1.47779243  1.80518716\n",
      "  1.31669814  1.88714268  0.12142905  1.89051299  1.48950406  1.9263772\n",
      "  0.1079189   0.03803772  1.89714844  1.19768404  0.23359411  1.03869615\n",
      "  0.08600836  1.76820966  1.63599689  1.23809019  1.24753714  1.85395852\n",
      "  1.19092247  0.08400373  1.06653983  0.9787747   1.47962541  0.09035968\n",
      "  0.1162084   1.99898246  1.29322945  1.68497162  1.52486499  1.89035381\n",
      "  1.29130439  1.80104268  1.21567214  0.04735014  0.20718966  1.00123471\n",
      "  0.1832903   0.84287758  1.16355703]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import BayesianRidge, LassoLars, LinearRegression\n",
    "\n",
    "vr = VotingRegressor(\n",
    "    estimators=[(\"BayesianRidge\", BayesianRidge()), (\"LassoLars\", LassoLars(alpha=0.05)),\n",
    "                (\"LinearRegression\", LinearRegression()),\n",
    "                (\"SVR\", svm.SVR())],\n",
    "    weights=[2, 1, 2, 1])\n",
    "\n",
    "vr.fit(data_train, target_train)\n",
    "\n",
    "print(vr.score(data_test, target_test))\n",
    "print(cross_val_score(vr, data_test, target_test, cv=5).mean())\n",
    "print(cross_val_predict(vr, data_test, target_test, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
