{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [1 0 2]\n",
      " [2 1 0]\n",
      " [3 4 5]\n",
      " [4 3 5]\n",
      " [5 4 3]]\n",
      "[[0.         1.         2.23606798]\n",
      " [0.         1.         1.41421356]\n",
      " [0.         1.41421356 2.23606798]\n",
      " [0.         1.         2.23606798]\n",
      " [0.         1.         1.41421356]\n",
      " [0.         1.41421356 2.23606798]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "\n",
    "# default n_neighbors = 5, it has to be >= data.length\n",
    "nbrs = neighbors.NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(data)\n",
    "distances_to_data, indicesOf_data = nbrs.kneighbors(data)\n",
    "\n",
    "# length of each row of indicesOf_data is equal to n_neighbors\n",
    "print(indicesOf_data)  # indices of data. (i.e: if indices is [1 0 3], it means data[1], data[0] and data[3])\n",
    "# length of each row of distances_to_data is equal to n_neighbors\n",
    "print(distances_to_data)  # distance to each point. i.e: if indices is [1 0 3], it means:\n",
    "# [{distance to data[1]}, {distance to data[0]}, {distance to data[3]}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (0, 1)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (3, 3)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (3, 5)\t1.0\n",
      "  (4, 4)\t1.0\n",
      "  (4, 3)\t1.0\n",
      "  (4, 5)\t1.0\n",
      "  (5, 5)\t1.0\n",
      "  (5, 4)\t1.0\n",
      "  (5, 3)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(nbrs.kneighbors_graph(data))  # (A, B) $(A and B are neighbors or not)\n",
    "# i.e: there is a row: (2, 1) 1.0 -> are data[2] and data[1] neighbors or not? 1 means yes, 0 means no\n",
    "# (or return the possibility from 0.0 to 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4 5]\n",
      " [1 0 2 3 4 5]\n",
      " [2 1 0 3 4 5]\n",
      " [3 4 5 0 1 2]\n",
      " [4 3 5 0 1 2]\n",
      " [5 4 3 0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "# nbrs can use KD Tree rather than ball tree, which looks like this:\n",
    "kdt = neighbors.KDTree(data,\n",
    "                       leaf_size=30,  # only effects performance, won't affect result.\n",
    "                       metric='euclidean')\n",
    "print(kdt.query(data,\n",
    "                k=6,  # number of neighbors, can be at most data.length\n",
    "                return_distance=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n",
      "[8]\n"
     ]
    }
   ],
   "source": [
    "nc = neighbors.NearestCentroid()\n",
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "data2 = np.array([np.arange(0, 9), np.arange(0, 9)])\n",
    "data2 = data2.T\n",
    "target2 = np.arange(0, 9)\n",
    "\n",
    "nc.fit(data2, target2)\n",
    "svc.fit(data2, target2)\n",
    "\n",
    "print(nc.predict([[100000, -100]]))\n",
    "print(svc.predict([[100000, -100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.0\n",
      "  (0, 1)\t1.4142135623730951\n",
      "  (1, 1)\t0.0\n",
      "  (1, 0)\t1.4142135623730951\n",
      "  (2, 2)\t0.0\n",
      "  (2, 1)\t1.4142135623730951\n",
      "  (3, 3)\t0.0\n",
      "  (3, 2)\t1.4142135623730951\n",
      "  (4, 4)\t0.0\n",
      "  (4, 3)\t1.4142135623730951\n",
      "  (5, 5)\t0.0\n",
      "  (5, 4)\t1.4142135623730951\n",
      "  (6, 6)\t0.0\n",
      "  (6, 5)\t1.4142135623730951\n",
      "  (7, 7)\t0.0\n",
      "  (7, 6)\t1.4142135623730951\n",
      "  (8, 8)\t0.0\n",
      "  (8, 7)\t1.4142135623730951\n"
     ]
    }
   ],
   "source": [
    "knt_d = neighbors.KNeighborsTransformer(n_neighbors=1, mode='distance')\n",
    "# prints: (point A, point B) $(distance)\n",
    "print(knt_d.fit_transform(data2, target2))  # either (point itself, point itself), or (point A, point B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 3)\t1.0\n",
      "  (4, 4)\t1.0\n",
      "  (5, 5)\t1.0\n",
      "  (6, 6)\t1.0\n",
      "  (7, 7)\t1.0\n",
      "  (8, 8)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# prints: (point A, point B) $(is neighbor or not: 1 == yes, 0 == no). Just like the kneighbors_graph\n",
    "knt_c = neighbors.KNeighborsTransformer(n_neighbors=1, mode='connectivity')\n",
    "print(knt_c.fit_transform(data2, target2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.93530067  1.13984386]\n",
      " [-0.90978582  2.08680997]\n",
      " [-1.96860234 -1.74918355]\n",
      " [ 1.41836969 -0.46892847]\n",
      " [-1.20194288  0.37681371]\n",
      " [-0.10996824 -0.20864408]\n",
      " [-0.10996824 -0.20864408]\n",
      " [-0.10996824 -0.20864408]\n",
      " [ 2.05656538 -0.75942328]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "knt_d_i = make_pipeline(\n",
    "    knt_d,\n",
    "    # Isomap is a 降维 method, 用来提速\n",
    "    Isomap(neighbors_algorithm='brute'),\n",
    "    memory='./cache')\n",
    "\n",
    "print(knt_d_i.fit_transform(data2, target2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.31503177e-02  8.05822628e-17]\n",
      " [-9.54463712e-01  1.41421356e+00]\n",
      " [-9.54463712e-01 -1.41421356e+00]\n",
      " [ 1.09874981e+00 -3.60822483e-16]\n",
      " [-8.73164628e-01 -5.55111512e-17]\n",
      " [ 2.31503177e-02  1.66533454e-16]\n",
      " [ 2.31503177e-02 -3.88578059e-16]\n",
      " [ 2.31503177e-02  5.55111512e-17]\n",
      " [ 1.59074097e+00 -1.66533454e-16]]\n"
     ]
    }
   ],
   "source": [
    "knt_c_i = make_pipeline(\n",
    "    knt_c,\n",
    "    # Isomap is a 降维 method, 用来提速\n",
    "    Isomap(neighbors_algorithm='brute'),\n",
    "    memory='./cache')\n",
    "\n",
    "# 可得出来的是个什么鬼？？？\n",
    "print(knt_c_i.fit_transform(data2, target2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9619047619047619\n",
      "0.9333333333333333\n",
      "0.9238095238095239\n",
      "0.9714285714285714\n",
      "0.9523809523809523\n",
      "0.9142857142857143\n",
      "0.8714285714285714\n",
      "0.9619047619047619\n",
      "0.9047619047619048\n",
      "0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_i, targeti = load_iris(return_X_y=True)\n",
    "data_train, data_test, target_train, target_test = train_test_split(data_i, targeti, random_state=42,\n",
    "                                                                    stratify=targeti, test_size=0.7)\n",
    "\n",
    "nca = neighbors.NeighborhoodComponentsAnalysis(random_state=42)\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# 重新起一个，不然会打脸的 - -||\n",
    "# nca_knn = Pipeline([('nca', nca), ('knn', knn)])\n",
    "\n",
    "nca_knn = Pipeline([('nca', neighbors.NeighborhoodComponentsAnalysis(random_state=42)),\n",
    "                    ('knn', neighbors.KNeighborsClassifier(n_neighbors=3))])\n",
    "nca_knn.fit(data_train, target_train)\n",
    "# nca_knn.fit(data2, target2)\n",
    "knn.fit(data_train, target_train)\n",
    "nc.fit(data_train, target_train)\n",
    "svc.fit(data_train, target_train)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "bay = GaussianNB()\n",
    "\n",
    "bay.fit(data_train, target_train)\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "dt_clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "dt_clf.fit(data_train, target_train)\n",
    "\n",
    "dt_reg = tree.DecisionTreeRegressor()  # 极端不稳定\n",
    "dt_reg.fit(data_train, target_train)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "# ensemble means \"vote\"\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "bagging = BaggingClassifier(max_samples=0.5,  # half rows\n",
    "                            max_features=0.5,  # half columns\n",
    "                            base_estimator=KNeighborsClassifier())\n",
    "\n",
    "# better than Bagging: can define how many estimators, rather than unknown number of estimators\n",
    "# worse than Bagging: cannot define the base_estimator\n",
    "\n",
    "rndForest = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "exTree = ExtraTreesClassifier(max_samples=0.5,  # half rows\n",
    "                              max_features=0.5,  # half columns\n",
    "                              n_estimators=10)\n",
    "\n",
    "bagging.fit(data_train, target_train)\n",
    "rndForest.fit(data_train, target_train)\n",
    "exTree.fit(data_train, target_train)\n",
    "\n",
    "print(nca_knn.score(data_test, target_test))\n",
    "print(knn.score(data_test, target_test))\n",
    "print(nc.score(data_test, target_test))\n",
    "print(svc.score(data_test, target_test))\n",
    "print(bay.score(data_test, target_test))\n",
    "print(dt_clf.score(data_test, target_test))\n",
    "print(dt_reg.score(data_test, target_test))\n",
    "print(bagging.score(data_test, target_test))\n",
    "print(rndForest.score(data_test, target_test))\n",
    "print(exTree.score(data_test, target_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
